{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8211990,"sourceType":"datasetVersion","datasetId":4866768},{"sourceId":8214658,"sourceType":"datasetVersion","datasetId":4868819},{"sourceId":8217419,"sourceType":"datasetVersion","datasetId":4870823},{"sourceId":8233193,"sourceType":"datasetVersion","datasetId":4882832},{"sourceId":8372973,"sourceType":"datasetVersion","datasetId":4977940}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-21T06:13:10.242214Z","iopub.status.idle":"2024-05-21T06:13:10.242522Z","shell.execute_reply.started":"2024-05-21T06:13:10.242369Z","shell.execute_reply":"2024-05-21T06:13:10.242382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python -m pip install transformers llama-index llama-index-llms-huggingface llama-index-embeddings-huggingface\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T06:13:10.243896Z","iopub.status.idle":"2024-05-21T06:13:10.244326Z","shell.execute_reply.started":"2024-05-21T06:13:10.244100Z","shell.execute_reply":"2024-05-21T06:13:10.244117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install accelerate","metadata":{"execution":{"iopub.status.busy":"2024-05-21T06:13:10.246025Z","iopub.status.idle":"2024-05-21T06:13:10.246331Z","shell.execute_reply.started":"2024-05-21T06:13:10.246181Z","shell.execute_reply":"2024-05-21T06:13:10.246193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%pip install llama-index-llms-huggingface\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T06:13:10.247555Z","iopub.status.idle":"2024-05-21T06:13:10.247904Z","shell.execute_reply.started":"2024-05-21T06:13:10.247743Z","shell.execute_reply":"2024-05-21T06:13:10.247757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install llama-index\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T06:13:10.249132Z","iopub.status.idle":"2024-05-21T06:13:10.249472Z","shell.execute_reply.started":"2024-05-21T06:13:10.249290Z","shell.execute_reply":"2024-05-21T06:13:10.249310Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install langchain","metadata":{"execution":{"iopub.status.busy":"2024-05-21T06:13:10.250857Z","iopub.status.idle":"2024-05-21T06:13:10.251156Z","shell.execute_reply.started":"2024-05-21T06:13:10.251008Z","shell.execute_reply":"2024-05-21T06:13:10.251020Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !mkdir -p 'data/paul_graham/'\n# !wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay.txt'","metadata":{"execution":{"iopub.status.busy":"2024-05-21T06:13:10.252260Z","iopub.status.idle":"2024-05-21T06:13:10.252562Z","shell.execute_reply.started":"2024-05-21T06:13:10.252413Z","shell.execute_reply":"2024-05-21T06:13:10.252425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install colored\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T06:13:10.253997Z","iopub.status.idle":"2024-05-21T06:13:10.254311Z","shell.execute_reply.started":"2024-05-21T06:13:10.254155Z","shell.execute_reply":"2024-05-21T06:13:10.254168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%pip install llama-index-vector-stores-chroma\n%pip install llama-index-embeddings-huggingface","metadata":{"execution":{"iopub.status.busy":"2024-05-21T06:13:10.255521Z","iopub.status.idle":"2024-05-21T06:13:10.255853Z","shell.execute_reply.started":"2024-05-21T06:13:10.255687Z","shell.execute_reply":"2024-05-21T06:13:10.255708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!huggingface-cli login --token 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","metadata":{"execution":{"iopub.status.busy":"2024-05-21T06:13:10.256961Z","iopub.status.idle":"2024-05-21T06:13:10.257252Z","shell.execute_reply.started":"2024-05-21T06:13:10.257105Z","shell.execute_reply":"2024-05-21T06:13:10.257117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install langchain","metadata":{"execution":{"iopub.status.busy":"2024-05-21T06:13:10.258123Z","iopub.status.idle":"2024-05-21T06:13:10.258416Z","shell.execute_reply.started":"2024-05-21T06:13:10.258268Z","shell.execute_reply":"2024-05-21T06:13:10.258280Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install langchain_experimental ","metadata":{"execution":{"iopub.status.busy":"2024-05-21T06:13:10.259700Z","iopub.status.idle":"2024-05-21T06:13:10.260017Z","shell.execute_reply.started":"2024-05-21T06:13:10.259861Z","shell.execute_reply":"2024-05-21T06:13:10.259874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install streamlit","metadata":{"execution":{"iopub.status.busy":"2024-05-21T06:13:10.261358Z","iopub.status.idle":"2024-05-21T06:13:10.261709Z","shell.execute_reply.started":"2024-05-21T06:13:10.261521Z","shell.execute_reply":"2024-05-21T06:13:10.261534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # from langchain.agents import create_csv_agent\n# from  langchain_experimental.agents import create_csv_agent\n# from langchain.llms import OpenAI\n# import streamlit as st\n# import os\n# import tempfile","metadata":{"execution":{"iopub.status.busy":"2024-05-21T06:13:10.262998Z","iopub.status.idle":"2024-05-21T06:13:10.263428Z","shell.execute_reply.started":"2024-05-21T06:13:10.263202Z","shell.execute_reply":"2024-05-21T06:13:10.263219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport pickle\n\nfrom google.auth.transport.requests import Request\n\nfrom google_auth_oauthlib.flow import InstalledAppFlow\n# from llama_index import GPTSimpleVectorIndex, download_loader\n# from langchain import OpenAI\nfrom llama_index.core import GPTVectorStoreIndex, PromptHelper, ServiceContext\n# from llama_index import LLMPredictor\nfrom colored import fg\n\nimport logging\nimport sys\n\n\nlogging.basicConfig(stream=sys.stdout, level=logging.INFO)\nlogging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n\nfrom llama_index.core import VectorStoreIndex, SimpleDirectoryReader\nfrom llama_index.llms.huggingface import HuggingFaceLLM\nfrom llama_index.core import Settings\nfrom llama_index.embeddings.huggingface import HuggingFaceEmbedding\nfrom llama_index.core import VectorStoreIndex, SimpleDirectoryReader\nfrom llama_index.core import Settings\nfrom llama_index.vector_stores.chroma import ChromaVectorStore\nfrom llama_index.core import StorageContext\nfrom llama_index.embeddings.huggingface import HuggingFaceEmbedding\nfrom IPython.display import Markdown, display\nimport chromadb\n# llama index to store data to Chroma vector Database local\nfrom llama_index.embeddings.huggingface import HuggingFaceEmbedding\nfrom llama_index.core import VectorStoreIndex, SimpleDirectoryReader\nfrom llama_index.core import Settings\nfrom llama_index.vector_stores.chroma import ChromaVectorStore\nfrom llama_index.core import StorageContext\nfrom llama_index.embeddings.huggingface import HuggingFaceEmbedding\nfrom IPython.display import Markdown, display\nimport chromadb\nfrom llama_index.core.node_parser import (\n    SentenceSplitter\n)\nfrom llama_index.core import ServiceContext","metadata":{"execution":{"iopub.status.busy":"2024-05-21T06:13:10.265188Z","iopub.status.idle":"2024-05-21T06:13:10.265617Z","shell.execute_reply.started":"2024-05-21T06:13:10.265406Z","shell.execute_reply":"2024-05-21T06:13:10.265423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load documents\ndocuments = SimpleDirectoryReader(\"/kaggle/input/bookdata/New folder\").load_data()\n# /kaggle/input/dataset2 /kaggle/input/newdataset","metadata":{"execution":{"iopub.status.busy":"2024-05-21T06:13:10.266839Z","iopub.status.idle":"2024-05-21T06:13:10.267273Z","shell.execute_reply.started":"2024-05-21T06:13:10.267043Z","shell.execute_reply":"2024-05-21T06:13:10.267061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!huggingface-cli login --token hf_fKUHEBUdjfvfCX***************","metadata":{"execution":{"iopub.status.busy":"2024-05-21T06:13:10.269240Z","iopub.status.idle":"2024-05-21T06:13:10.269648Z","shell.execute_reply.started":"2024-05-21T06:13:10.269437Z","shell.execute_reply":"2024-05-21T06:13:10.269453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from llama_index.core import PromptTemplate\nsystem_prompt = \"\"\"\nContext information is below.\n- You are a Q&A assistant. Your goal is to answer questions as\naccurately as possible based on the instructions and context provided from our document.\n- Given the context information and not prior knowledge, answer the query.\n- Please write the answer in the style of Human Like\nQuery:\nAnswer: \n\"\"\"\n\nquery_wrapper_prompt = PromptTemplate('\"<|USER|>{query_str}<|ASSISTANT|>\"')\n\n# partial_prompt_tmpl = prompt_tmpl.partial_format(tone_name=\"Human Like\")\n\n# partial_prompt_tmpl.kwargs","metadata":{"execution":{"iopub.status.busy":"2024-05-21T06:13:10.271048Z","iopub.status.idle":"2024-05-21T06:13:10.271465Z","shell.execute_reply.started":"2024-05-21T06:13:10.271246Z","shell.execute_reply":"2024-05-21T06:13:10.271263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n\nllm = HuggingFaceLLM(\n    context_window=4096,\n    max_new_tokens=300,\n    generate_kwargs={\"temperature\": 0.4, \"do_sample\": False},\n    system_prompt=system_prompt,\n    query_wrapper_prompt=query_wrapper_prompt,\n    tokenizer_name= \"meta-llama/Llama-2-7b-chat-hf\", #meta-llama/Meta-Llama-3-8B\", #\"meta-llama/Llama-2-7b-chat-hf\", HuggingFaceH4/zephyr-7b-alpha\n    model_name=\"meta-llama/Llama-2-7b-chat-hf\",\n    device_map=\"auto\",\n#     stopping_ids=[50278, 50279, 50277, 1, 0],\n    tokenizer_kwargs={\"max_length\": 4096},\n#     uncomment this if using CUDA to reduce memory usage\n#     model_kwargs={\"torch_dtype\": torch.float16}\n)\n\n# torch.set_default_tensor_type(torch.cuda.HalfTensor)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T06:13:10.272758Z","iopub.status.idle":"2024-05-21T06:13:10.273183Z","shell.execute_reply.started":"2024-05-21T06:13:10.272966Z","shell.execute_reply":"2024-05-21T06:13:10.272984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install chromadb","metadata":{"execution":{"iopub.status.busy":"2024-05-21T06:13:10.274629Z","iopub.status.idle":"2024-05-21T06:13:10.275083Z","shell.execute_reply.started":"2024-05-21T06:13:10.274892Z","shell.execute_reply":"2024-05-21T06:13:10.274912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n# define embedding function\n# embed_model = HuggingFaceEmbedding(model_name=\"sentence-transformers/all-mpnet-base-v2\")\nembed_model = HuggingFaceEmbedding(model_name=\"sentence-transformers/all-mpnet-base-v2\")\nSettings.embed_model = embed_model\nSettings.chunk_size = 516\nSettings.chunk_overlap = 20\n\n\nsplitter = SentenceSplitter(\n    chunk_size=516,\n    chunk_overlap=20,\n)\nnodes = splitter.get_nodes_from_documents(documents)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T06:13:10.276392Z","iopub.status.idle":"2024-05-21T06:13:10.276763Z","shell.execute_reply.started":"2024-05-21T06:13:10.276565Z","shell.execute_reply":"2024-05-21T06:13:10.276579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"db = chromadb.PersistentClient(path=\"./chroma_db\")\nchroma_collection = db.get_or_create_collection(\"quickstart\")\nvector_store = ChromaVectorStore(chroma_collection=chroma_collection)\nstorage_context = StorageContext.from_defaults(vector_store=vector_store)\nservice_context=ServiceContext.from_defaults(chunk_size=516,chunk_overlap=20,llm=llm,embed_model=Settings.embed_model)\n\n\nindex=VectorStoreIndex.from_documents(documents,service_context=service_context, storage_context=storage_context, embed_model=embed_model, transformations=[splitter],SentenceSplitter=nodes)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T06:13:10.277681Z","iopub.status.idle":"2024-05-21T06:13:10.278027Z","shell.execute_reply.started":"2024-05-21T06:13:10.277862Z","shell.execute_reply":"2024-05-21T06:13:10.277876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Query Data\nquery_engine = index.as_query_engine(streaming=True, similarity_top_k=1)\nresponse_stream = query_engine.query(\"What is the book the Alchemist is about??\")","metadata":{"execution":{"iopub.status.busy":"2024-05-21T06:13:10.278993Z","iopub.status.idle":"2024-05-21T06:13:10.279284Z","shell.execute_reply.started":"2024-05-21T06:13:10.279136Z","shell.execute_reply":"2024-05-21T06:13:10.279148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"response_stream.print_response_stream()","metadata":{"execution":{"iopub.status.busy":"2024-05-21T06:13:10.280589Z","iopub.status.idle":"2024-05-21T06:13:10.280945Z","shell.execute_reply.started":"2024-05-21T06:13:10.280790Z","shell.execute_reply":"2024-05-21T06:13:10.280803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.set_default_tensor_type(torch.cuda.HalfTensor)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T06:13:10.286267Z","iopub.status.idle":"2024-05-21T06:13:10.286580Z","shell.execute_reply.started":"2024-05-21T06:13:10.286425Z","shell.execute_reply":"2024-05-21T06:13:10.286438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nest_asyncio\n\nnest_asyncio.apply()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from llama_index.core.evaluation import FaithfulnessEvaluator\nfrom llama_index.core.evaluation import RetrieverEvaluator\n\nevaluator = FaithfulnessEvaluator(llm=llm)\n\nquery_engine = index.as_query_engine(similarity_top_k=1 )\nquery=str(input(''))\nresponse = query_engine.query(query)\neval_result =  evaluator.evaluate_response(response=response,query=query)\nprint(str(eval_result.passing))\n\nif eval_result.passing == True:\n#     response = query_engine.query(query)\n    print(response)\nelse:\n    print(\"This is not mentioned in the context information, so it is not possible to answer the question.\")","metadata":{"execution":{"iopub.status.busy":"2024-05-21T06:13:10.288168Z","iopub.status.idle":"2024-05-21T06:13:10.288487Z","shell.execute_reply.started":"2024-05-21T06:13:10.288330Z","shell.execute_reply":"2024-05-21T06:13:10.288344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from llama_index.core.evaluation import EvaluationResult\n\n\n# define jupyter display function\ndef display_eval_df(\n    query: str, response, eval_result: EvaluationResult\n) -> None:\n    eval_df = pd.DataFrame(\n        {\n            \"Query\": query,\n            \"Response\": str(response),\n            \"Source\": response.source_nodes[0].node.text[:1000] + \"...\",\n            \"Evaluation Result\": \"Pass\" if eval_result.passing else \"Fail\",\n            \"Reasoning\": eval_result.feedback,\n        },\n        index=[0],\n    )\n    eval_df = eval_df.style.set_properties(\n        **{\n            \"inline-size\": \"600px\",\n            \"overflow-wrap\": \"break-word\",\n        },\n        subset=[\"Response\", \"Source\"]\n    )\n    display(eval_df)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T06:13:10.290948Z","iopub.status.idle":"2024-05-21T06:13:10.291263Z","shell.execute_reply.started":"2024-05-21T06:13:10.291107Z","shell.execute_reply":"2024-05-21T06:13:10.291120Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # # from llama_index import GPTVectorStoreIndex\nfrom llama_index.core.evaluation import FaithfulnessEvaluator\nfrom llama_index.core.evaluation import RetrieverEvaluator\n\n# build service context\n# llm_predictor = LLMPredictor(llm=ChatOpenAI(temperature=0, model_name=\"gpt-4\"))\n# service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor)\n\n# build index\n...\n\n# define evaluator\nevaluator = FaithfulnessEvaluator(llm=llm)\n# evaluator2 = ResponseEvaluator(service_context=service_context)\n\n# query index\nquery_engine = index.as_query_engine(similarity_top_k=1 )\nquery=\"What is the book the Alchemist is about?\"\nresponse = query_engine.query(query)\neval_result =  evaluator.evaluate_response(response=response,query=query)\nprint(str(eval_result.passing))\n\n# retriever_evaluator = RetrieverEvaluator.from_metric_names( [\"mrr\", \"hit_rate\"], retriever=query_engine)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T06:13:10.292496Z","iopub.status.idle":"2024-05-21T06:13:10.292835Z","shell.execute_reply.started":"2024-05-21T06:13:10.292641Z","shell.execute_reply":"2024-05-21T06:13:10.292672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_eval_df(query, response, eval_result)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T06:13:10.295359Z","iopub.status.idle":"2024-05-21T06:13:10.295829Z","shell.execute_reply.started":"2024-05-21T06:13:10.295566Z","shell.execute_reply":"2024-05-21T06:13:10.295583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-05-21T06:13:10.304004Z","iopub.status.idle":"2024-05-21T06:13:10.304320Z","shell.execute_reply.started":"2024-05-21T06:13:10.304163Z","shell.execute_reply":"2024-05-21T06:13:10.304177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}